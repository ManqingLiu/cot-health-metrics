"""
Unit tests for gpt-oss-20b do_split parsing logic.

Tests the extraction of r.question, r.prompt, r.cot, and r.answer
using fuzzy matching with Answer: delimiter.

These tests verify the parsing logic WITHOUT requiring GPU or model loading.
"""

import pytest
import sys
import os

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from config import ModelConfig


class TestGptOss20bDoSplitLogic:
    """Test the do_split parsing logic for gpt-oss-20b."""

    def get_config(self):
        """Get gpt-oss-20b config."""
        return ModelConfig.get("openai/gpt-oss-20b")

    def simulate_do_split(self, generated_text: str, expect_cot: bool = True):
        """
        Simulate the do_split logic for gpt-oss-20b using fuzzy matching.

        Args:
            generated_text: The text generated by the model (after prompt)
            expect_cot: Whether to expect CoT in output

        Returns:
            Tuple of (cot, answer)
        """
        config = self.get_config()

        if "fuzzy_end_think_list" not in config:
            raise ValueError("Config must have fuzzy_end_think_list")

        fuzzy_list = config["fuzzy_end_think_list"]

        for delimiter in fuzzy_list:
            parts = generated_text.split(delimiter, 1)
            if len(parts) == 2:
                cot = parts[0].strip()
                answer = parts[1].strip()
                return (cot, answer)

        if expect_cot:
            raise RuntimeError(f"Not enough pieces to split, couldn't find delimiter in {fuzzy_list}")
        else:
            return ("", generated_text.strip())

    def test_basic_split(self):
        """Test basic splitting with Answer: delimiter."""
        generated_text = "This is the reasoning step by step.\nAnswer: sun"

        cot, answer = self.simulate_do_split(generated_text)

        assert cot == "This is the reasoning step by step."
        assert answer == "sun"

    def test_multiline_cot(self):
        """Test splitting with multiline CoT content."""
        generated_text = """Step 1: Analyze the problem
Step 2: Consider the options
Step 3: Draw a conclusion

Answer: B"""

        cot, answer = self.simulate_do_split(generated_text)

        assert "Step 1" in cot
        assert "Step 2" in cot
        assert "Step 3" in cot
        assert answer == "B"

    def test_calendar_arithmetic_example(self):
        """Test with calendar arithmetic task output."""
        generated_text = """We need business days Monday-Friday inclusive.
Starting from Monday, counting 1 day forward.
Monday + 1 = Tuesday.
So the answer encoded as sun.

Answer: sun"""

        cot, answer = self.simulate_do_split(generated_text)

        assert "business days Monday-Friday" in cot
        assert "encoded as sun" in cot
        assert answer == "sun"

    def test_binary_alternation_example(self):
        """Test with binary alternation task output."""
        generated_text = """Given the binary string '10101'.
Checking if it's already alternating: 1-0-1-0-1.
Yes, it alternates perfectly.
Minimum swaps needed: 0.

Answer: 0"""

        cot, answer = self.simulate_do_split(generated_text)

        assert "binary string '10101'" in cot
        assert "alternating" in cot
        assert answer == "0"

    def test_spell_backward_example(self):
        """Test with spell backward task output."""
        generated_text = """The word is 'hello'.
Letters: h-e-l-l-o
Reversing: o-l-l-e-h

Answer: olleh"""

        cot, answer = self.simulate_do_split(generated_text)

        assert "word is 'hello'" in cot
        assert "Reversing" in cot
        assert answer == "olleh"

    def test_inline_answer(self):
        """Test when Answer: is inline without leading newline."""
        generated_text = "The sum is 4. Answer: 4"

        cot, answer = self.simulate_do_split(generated_text)

        assert "The sum is 4" in cot
        assert answer == "4"

    def test_answer_with_newlines_after(self):
        """Test answer extraction when there are newlines after delimiter."""
        generated_text = """Complex reasoning here.
Multiple lines of thought.

Answer: 42"""

        cot, answer = self.simulate_do_split(generated_text)

        assert "Complex reasoning" in cot
        assert answer == "42"

    def test_special_characters_in_cot(self):
        """Test CoT with special characters."""
        generated_text = """Formula: x = (a + b) / 2
Where a = 10 and b = 20
x = (10 + 20) / 2 = 15

Answer: 15"""

        cot, answer = self.simulate_do_split(generated_text)

        assert "x = (a + b) / 2" in cot
        assert answer == "15"

    def test_answer_is_clean_no_reasoning(self):
        """Verify the answer is clean without any reasoning trace."""
        generated_text = """I need to think about this carefully.
Let me analyze step by step.
First, consider the inputs.
Then, apply the logic.
The answer is clearly 42.

Answer: 42"""

        cot, answer = self.simulate_do_split(generated_text)

        # Answer should be clean
        assert answer == "42"

        # Answer should not contain reasoning phrases
        assert "think" not in answer.lower()
        assert "step" not in answer.lower()
        assert "consider" not in answer.lower()

        # All the reasoning should be in CoT
        assert "think about this" in cot
        assert "step by step" in cot

    def test_missing_delimiter_raises_error(self):
        """Test that missing delimiter raises error."""
        generated_text = "This is just raw text without any delimiter"

        with pytest.raises(RuntimeError) as exc_info:
            self.simulate_do_split(generated_text)

        assert "Not enough pieces to split" in str(exc_info.value)

    def test_missing_delimiter_no_cot_expected(self):
        """Test fallback when no CoT is expected."""
        generated_text = "This is just raw text"

        cot, answer = self.simulate_do_split(generated_text, expect_cot=False)

        assert cot == ""
        assert answer == "This is just raw text"


class TestGptOss20bAnswerCleanliness:
    """Tests specifically for answer cleanliness."""

    def get_config(self):
        return ModelConfig.get("openai/gpt-oss-20b")

    def extract_answer(self, generated_text: str) -> str:
        """Extract just the answer portion using fuzzy matching."""
        config = self.get_config()
        fuzzy_list = config["fuzzy_end_think_list"]

        for delimiter in fuzzy_list:
            parts = generated_text.split(delimiter, 1)
            if len(parts) == 2:
                return parts[1].strip()
        return generated_text.strip()

    def test_answer_no_harmony_tokens(self):
        """Verify answer doesn't contain harmony format tokens."""
        test_cases = [
            "Reasoning here.\nAnswer: 42",
            "Long chain of thought.\nAnswer: Paris",
            "Many steps.\nAnswer: True",
            "Analysis complete.\nAnswer: olleh",
        ]

        for case in test_cases:
            answer = self.extract_answer(case)
            assert "<|start|>" not in answer, f"Answer contains <|start|>: {answer}"
            assert "<|end|>" not in answer, f"Answer contains <|end|>: {answer}"
            assert "<|channel|>" not in answer, f"Answer contains <|channel|>: {answer}"

    def test_answer_various_types(self):
        """Test answer extraction for various answer types."""
        test_cases = [
            ("CoT here.\nAnswer: 42", "42"),  # Number
            ("CoT here.\nAnswer: Paris", "Paris"),  # Word
            ("CoT here.\nAnswer: True", "True"),  # Boolean
            ("CoT here.\nAnswer: olleh", "olleh"),  # Reversed string
            ("CoT here.\nAnswer: sun", "sun"),  # Encoded answer
            ("CoT here.\nAnswer: Thursday", "Thursday"),  # Day of week
        ]

        for generated_text, expected in test_cases:
            answer = self.extract_answer(generated_text)
            assert answer == expected, f"Expected '{expected}', got '{answer}'"


class TestGptOss20bFullResponseSimulation:
    """Simulate full response parsing like model.py generate_cot_response_full."""

    def get_config(self):
        return ModelConfig.get("openai/gpt-oss-20b")

    def simulate_full_response_parsing(self, question: str, generated_text: str):
        """
        Simulate the full response parsing that creates ModelResponse.

        Returns a dict with question, prompt, cot, answer, raw_output.
        """
        config = self.get_config()
        fuzzy_list = config["fuzzy_end_think_list"]

        # Simulate prompt building (simplified)
        prompt = f"Question: {question}\n"

        # The raw_output would include both prompt and generation
        raw_output = prompt + generated_text

        # Parse the generated text using fuzzy matching
        for delimiter in fuzzy_list:
            parts = generated_text.split(delimiter, 1)
            if len(parts) == 2:
                cot = parts[0].strip()
                answer = parts[1].strip()
                return {
                    "question": question,
                    "prompt": prompt,
                    "cot": cot,
                    "answer": answer,
                    "raw_output": raw_output
                }

        raise RuntimeError("Could not split")

    def test_full_response_all_fields(self):
        """Test that all ModelResponse fields are correctly populated."""
        question = "What is 2 + 2?"
        generated_text = "Let me add 2 and 2. The sum is 4.\nAnswer: 4"

        r = self.simulate_full_response_parsing(question, generated_text)

        # Verify all fields
        assert r["question"] == question
        assert "Question: What is 2 + 2?" in r["prompt"]
        assert "Let me add 2 and 2" in r["cot"]
        assert r["answer"] == "4"
        assert len(r["raw_output"]) > len(r["prompt"])

    def test_answer_is_clean_in_full_response(self):
        """Ensure answer is clean when extracted from full response."""
        question = "Spell 'cat' backwards"
        generated_text = """The word is 'cat'.
Letters: c-a-t (3 letters)
Reversing: t-a-c

Answer: tac"""

        r = self.simulate_full_response_parsing(question, generated_text)

        # Answer should be exactly "tac"
        assert r["answer"] == "tac"

        # Answer should not contain any tokens or reasoning
        assert "Reversing" not in r["answer"]
        assert "Letters" not in r["answer"]

        # CoT should contain the reasoning
        assert "Letters: c-a-t" in r["cot"]
        assert "Reversing: t-a-c" in r["cot"]


if __name__ == "__main__":
    pytest.main([__file__, "-v"])
